{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import MeCab\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import neologdn\n",
    "import demoji\n",
    "import emoji\n",
    "\n",
    "model_dir = '/Users/iomacbookair2/Documents/lab/DEIM2023/entity_vector/entity_vector.model.bin'\n",
    "# model_dir = '/Users/labimac/Documents/lab/DEIM2023/entity_vector/entity_vector.model.bin'\n",
    "model_word2vec = KeyedVectors.load_word2vec_format(model_dir, binary=True)\n",
    "mecab = MeCab.Tagger('-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/iomacbookair2/Documents/lab/DEIM2023/tweet_csv/nichiten/230115_nichiten.csv\"\n",
    "# path = \"/Users/labimac/Documents/lab/DEIM2023/tweet_csv/221214_ann_wed.csv\"\n",
    "\n",
    "df = pd.read_csv((path))\n",
    "df.sort_values(by = 'created_at', ascending = True, inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df = df.drop(\"author_id\", axis=1)\n",
    "df = df.drop(\"username\", axis=1)\n",
    "df = df.drop(\"tweet_id\", axis=1)\n",
    "df = df.drop(\"like_count\", axis=1)\n",
    "df = df.drop(\"retweet_count\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = emoji.replace_emoji(text, replace=' ')\n",
    "    text = re.sub(r'#\\S+', '', text) # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'ï¼ƒ\\S+', '', text) # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'@\\S+', '', text) # @ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'http?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+', '', text) # URLã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®ãæ›ãˆ\n",
    "    text = re.sub(r'https?://\\S+', ' ', text) # URLã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®ãæ›ãˆ\n",
    "    text = re.sub(r'!-/:-@[-`{-~]', r'', text) # è¨˜å·ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'â€', '', text)  # \"ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'\"', '', text)  # \"ã‚’æ¶ˆã™\n",
    "    text = re.sub(r\"'\", \"\", text) # 'ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'[(-`)]', '', text)\n",
    "    text = re.sub(\n",
    "        \"[\\uFF01-\\uFF0F\\uFF1A-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\u3000-\\u303F]\", '', text)  # è¨˜å·ã‚’æ¶ˆã™\n",
    "    text = re.sub(\n",
    "        u'[â– -â™¯ã€ã€‘ã€Œã€ã€ã€;ãƒ»ã…‚ï¾ŸËŠá—œâ”â”â”“â”—â”›ãƒ¾Î¸ã€â”‚!-/`:-@-`{-~ã€‚|âˆ€!ã€‡â•°`â€²â€µË‹Ï‰.*ãƒ¼â€¦â•­âˆ‡^_ï¿£Â´ï½€â€¢Ë˜Ğ´â†‘è‰¸â•¯â†’Â°Ğ´Ì€á´—ËƒË‚â½â¾Ï†â””ï¼¼â€»å½¡ğ–¥¦â†ê‚¹]', '', text)  # è¨˜å·ã‚’æ¶ˆã™\n",
    "    text = re.sub(r'(\\d)([,.])(\\d+)', r'\\1\\3', text) # å°æ•°ç‚¹ã¨ã‚«ãƒ³ãƒã‚’æ¶ˆã™\n",
    "    text = re.sub(r'\\d+', '0', text) # æ•°å­—ã‚’0ã«ç½®ãæ›ãˆ\n",
    "    text = text.lower() # è‹±å­—ã‚’å°æ–‡å­—ã«\n",
    "    text = re.sub(r\"[\\u3000\\t\\r\\n]\", \" \", text) # ç©ºç™½æ–‡å­—ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®ãæ›ãˆ\n",
    "    text = neologdn.normalize(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('220115_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vec(sentence, model, mecab):\n",
    "    if not sentence:\n",
    "        sentence_embedding = np.zeros(200, dtype=np.float32)\n",
    "    else:\n",
    "        pre_sentence = sentence.split(\" \")\n",
    "        sentence_words = []\n",
    "        for s in pre_sentence:\n",
    "            sentence_words += [line.split(\"\\t\")[0]\n",
    "                               for line in mecab.parse(s).split(\"\\n\")[:-2]]\n",
    "        if all(re.match(r'.*[a-zA-Z].*', word) for word in sentence_words):\n",
    "            sentence_embedding = np.zeros(200, dtype=np.float32)\n",
    "        else:\n",
    "            word_vectors = [model[word]\n",
    "                            for word in sentence_words if word in model]\n",
    "            if word_vectors:\n",
    "                if len(word_vectors) == 0:\n",
    "                    sentence_embedding = np.zeros(200, dtype=np.float32)\n",
    "                else:\n",
    "                    sentence_embedding = np.mean(word_vectors, axis=0)\n",
    "            else:\n",
    "                sentence_embedding = np.zeros(200, dtype=np.float32)\n",
    "    return sentence_embedding\n",
    "\n",
    "df[\"vector\"] = df[\"text\"].apply(\n",
    "    lambda x: 0 if len(x) <= 1 else word_to_vec(x, model_word2vec, mecab))\n",
    "df = df.drop(\"text\", axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('220115_vector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(pd.Grouper(key='created_at', freq='min'))\n",
    "df_vectors = pd.DataFrame({\n",
    "    \"vectors\": groups.apply(lambda x: x[\"vector\"].tolist())\n",
    "})\n",
    "df_vectors = df_vectors.reset_index()\n",
    "df_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors.to_csv('220115_vector_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(vector1, vector2):\n",
    "  similarity = cosine_similarity(\n",
    "      vector1, vector1, vector2)[0][0]\n",
    "  return similarity\n",
    "\n",
    "\n",
    "def calc_average_similarity(vectors, key):\n",
    "    similarities = []\n",
    "    for i in range(len(vectors)):\n",
    "        for j in range(i + 1, len(vectors)):\n",
    "            print(f'i={i},j={j}')\n",
    "            if np.all(vectors[i] == 0) or np.all(vectors[j] == 0):\n",
    "                similarity = 0\n",
    "            else:\n",
    "                similarity = calc_similarity(vectors[i].reshape(1, -1), vectors[j].reshape(1, -1))\n",
    "            print(similarity)\n",
    "            similarities.append(similarity)\n",
    "    q = [0, 0.25, 0.5, 0.75, 1]\n",
    "    outputs = {}\n",
    "    for i in range(len(q)):\n",
    "        outputs[f\"q{i}\"] = np.quantile(similarities, q[i])\n",
    "    outputs[\"standard_deviation\"] = np.std(similarities)\n",
    "    outputs[\"mean\"] = np.mean(similarities)\n",
    "    if key == \"q2\":\n",
    "        return outputs[\"q2\"]\n",
    "    elif key == \"q1\":\n",
    "        return outputs[\"q1\"]\n",
    "    elif key == \"q3\":\n",
    "        return outputs[\"q3\"]\n",
    "    elif key == \"standard_deviation\":\n",
    "        return outputs[\"standard_deviation\"]\n",
    "    elif key == \"mean\":\n",
    "        return outputs[\"mean\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors[\"q1\"] = df_vectors[\"vectors\"].apply(\n",
    "    lambda x: 0 if len(x) <= 1 else calc_average_similarity(x, \"q1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors[\"q2\"] = df_vectors[\"vectors\"].apply(\n",
    "    lambda x: 0 if len(x) <= 1 else calc_average_similarity(x, \"q2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors[\"q3\"] = df_vectors[\"vectors\"].apply(\n",
    "    lambda x: 0 if len(x) <= 1 else calc_average_similarity(x, \"q3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors[\"stdev\"] = df_vectors[\"vectors\"].apply(\n",
    "    lambda x: 0 if len(x) <= 1 else calc_average_similarity(x, \"standard_deviation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = df_vectors.drop(\"vectors\", axis=1)\n",
    "df_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors.to_csv('220115_similarity.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_similarity_word2vec(sentence1, sentence2, model, mecab):\n",
    "#   pre_sentence1 = sentence1.split(\" \")\n",
    "#   sentence1_words = []\n",
    "#   for s1 in pre_sentence1:\n",
    "#     sentence1_words += [line.split(\"\\t\")[0]\n",
    "#                         for line in mecab.parse(s1).split(\"\\n\")[:-2]]\n",
    "#   pre_sentence2 = sentence2.split(\" \")\n",
    "#   sentence2_words = []\n",
    "#   for s2 in pre_sentence2:\n",
    "#     sentence2_words += [line.split(\"\\t\")[0]\n",
    "#                         for line in mecab.parse(s2).split(\"\\n\")[:-2]]\n",
    "#   if not sentence1_words and not sentence2_words:\n",
    "#     similarity = 1\n",
    "#   elif not sentence1_words or not sentence2_words:\n",
    "#     similarity = 0\n",
    "#   elif (len(sentence1_words) == 1 and len(sentence2_words) != 1) or (len(sentence2_words) == 1 and len(sentence1_words) != 1):\n",
    "#     similarity = 0\n",
    "#   elif all(re.match(r'.*[a-zA-Z].*', word) for word in sentence1_words) or all(re.match(r'.*[a-zA-Z].*', word) for word in sentence2_words):\n",
    "#     similarity = 0\n",
    "#   else:\n",
    "#     sentence1_embedding = np.mean([model[word]\n",
    "#                                   for word in sentence1_words if word in model], axis=0)\n",
    "#     sentence2_embedding = np.mean([model[word]\n",
    "#                                   for word in sentence2_words if word in model], axis=0)\n",
    "#     if np.isnan(sentence1_embedding).any() or np.isnan(sentence2_embedding).any():\n",
    "#         similarity = 0\n",
    "#     else:\n",
    "#       similarity = cosine_similarity(\n",
    "#           [sentence1_embedding], [sentence2_embedding])[0][0]\n",
    "#   return similarity\n",
    "\n",
    "\n",
    "# def calc_average_similarity_word2vec(sentences, key, mecab):\n",
    "#     similarities = []\n",
    "#     for i in range(len(sentences)):\n",
    "#         for j in range(i + 1, len(sentences)):\n",
    "#             similarity = calc_similarity_word2vec(\n",
    "#                 sentences[i], sentences[j], model_word2vec, mecab)\n",
    "#             similarities.append(similarity)\n",
    "#     q = [0, 0.25, 0.5, 0.75, 1]\n",
    "#     outputs = {}\n",
    "#     for i in range(len(q)):\n",
    "#         outputs[f\"quantile_{i}\"] = np.quantile(similarities, q[i])\n",
    "#     outputs[\"q1\"] = outputs[\"quantile_1\"]\n",
    "#     outputs[\"q2\"] = outputs[\"quantile_2\"]\n",
    "#     outputs[\"q3\"] = outputs[\"quantile_3\"]\n",
    "#     outputs[\"standard_deviation\"] = np.std(similarities)\n",
    "#     outputs[\"mean\"] = np.mean(similarities)\n",
    "#     if key == \"q2\":\n",
    "#         return outputs[\"quantile_2\"]\n",
    "#     elif key == \"q1\":\n",
    "#         return outputs[\"quantile_1\"]\n",
    "#     elif key == \"q3\":\n",
    "#         return outputs[\"quantile_3\"]\n",
    "#     elif key == \"standard_deviation\":\n",
    "#         return outputs[\"standard_deviation\"]\n",
    "#     elif key == \"mean\":\n",
    "#         return outputs[\"mean\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4251bd4dd34dd98bdf6c990c128a7244877d69ebc52d9147cbc19662179b2ef6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
